<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projet de RNN</title>
    <link rel="stylesheet" type="text/css" href="index.css">
</head>
<body>

    <header>
        <h1>Quest Quill</h1>
    </header>


    <nav>
        <a href="#generate">Manuel Quest Quill</a>
        <a href="#documentation">Documentation</a>
        <a href="#evaluation">Évaluation</a>
        <a href="#modelbert">Modèle BERT</a>
        <a href="#contact">Contact</a>
    </nav>

    <section id="generate" class="ai-section" style="position: relative;">
        <h2>Projet Quest Quill  </h2>
        <p style="text-align: justify;"><strong>Qu'est ce que c'est ?</strong></p>
        <div style="text-align: justify;">
                <p>Quest Quill est un générateur de quêtes automatiques . L'utilisateurs spécifie la carte ou il souhaite combatre, le monstre qu'il souhaite abattre ainsi que la difficulté de la quête.</p>
                <p>Suite aux indications données par l'utilisateurs, QUest Quill va générer une quête avec un contexte et un objectif à accomplir</p>
                <p style="text-align: justify;"><strong>Et pourquoi ?</strong></p>
                <p>Le monde étant en grand danger suite aux multiples attaques de monstres. Il nous a semblé urgent de nous entraîner à combattre à l'aide d'un générateur de quêtes automatiques. Les objectifs de cet entraînement sont, dans un premier temps générer des quetes avec des conditions telles que : map, difficulté, monstre. Dans un second temps les quetes devront avoir de la cohérence et de l'humour. Ce sont des quetes qui servent à divertir ! </p>
    
        

        <h2>Manuel Quest Quill</h2>
        <p style="text-align: justify;"><strong>Prérequis :</strong></p>
        <ul style="text-align: justify;">
            <li>Python 3.x installé sur votre système.</li>
            <li>Bibliothèque Transformers de Hugging Face installée (<code>pip install transformers</code>).</li>
            <li>Un modèle pré-entraîné GPT-2 et son tokenizer.</li>
            <li>FastAPI</li>
            <li>Uvicorn</li>
        </ul>
        <p style="text-align: justify;"> Comment lancer l'interface web ?</p>
        <p style="text-align: justify;"> se déplacer dans le terminal à l'endroit ou se trouve "main.py" ainsi que deux dossiers  static et modele</p>
        <p style="text-align: justify;"> lancer l'interface à l'aide de la commande ci dessous : </p>
        <p style="text-align: justify;"> python -m uvicorn main:app --reload</p>

        <p style="text-align: justify;"> Comment générer une quête une fois sur l'interface ?</p>
        <p style="text-align: justify;">Afin de générer la quête, il faut mentionner :</p>
    
                <ul style="text-align: justify;">
                    <li>La carte où se déroulera la quête pour pouvoir s'acclimater à divers environnements de combat.</li>
                    <li>La difficulté de la quête à choisir entre easy, medium, hard</li>
                    <li>Le ou les monstres à chasser.</li>
                </ul>
        <head>

            <style>
                table {
                    width: 100%;
                    border-collapse: collapse;
                }
                th, td {
                    border: 1px solid black;
                    padding: 8px;
                    text-align: left;
                }
                th {
                    background-color: #f2f2f2;
                }
            </style>
        </head>
        <body>
        
        <h2>Bestiaire A COMPLETER</h2>
        
        <table> 
            <tr>
                <td>Jagras</td>
                <td>Baggi</td>
                <td>Arzuros</td>
                <td>Great Baggi</td>
            </tr>
            <tr>
                <td>Lagombi</td>
                <td>Kulu-Ya-Ku</td>
                <td>Tetranadon</td>
                <td>Aknosom</td>
            </tr>
            <tr>
                <td>Great Izuchi</td>
                <td>Royal Ludroth</td>
                <td>Barroth</td>
                <td>Khezu</td>
            </tr>
            <tr>
                <td>Bishaten</td>
                <td>Somnacanth</td>
                <td>Pukei-Pukei</td>
                <td>Jyuratodus</td>
            </tr>
            <tr>
                <td>Basarios</td>
                <td>Rathian</td>
                <td>Tobi-Kadachi</td>
                <td>Volvidon</td>
            </tr>
            <tr>
                <td>Mizutsune</td>
                <td>Anjanath</td>
                <td>Rathalos</td>
                <td>Almudron</td>
            </tr>
            <tr>
                <td>Goss Harag</td>
                <td>Nargacuga</td>
                <td>Zinogre</td>
                <td>Magnamalo</td>
            </tr>
            <tr>
                <td>Tigrex</td>
                <td>Diablos</td>
                <td>Rajang</td>
                <td>Kushala Daora</td>
            </tr>
            <tr>
                <td>Teostra</td>
                <td>Chameleos</td>
                <td>Wind Serpent Ibushi</td>
                <td>Thunder Serpent Narwa</td>
            </tr>
            <tr>
                <td>Narwa the Allmother</td>
                <td>Crimson Glow Valstrax</td>
                <td>Apex Arzuros</td>
                <td>Apex Rathian</td>
            </tr>
            <tr>
                <td>Apex Mizutsune</td>
                <td>Apex Rathalos</td>
                <td>Apex Diablos</td>
                <td>Apex Zinogre</td>
            </tr>
        </table>
        
        </body>


        <h2>Map</h2>
        
    </section>
    
    
    <style>
        .sub-section {
            font-weight: bold;
        }
    </style>
    
    <section id="documentation" class="ai-section">
        <h2>Documentation</h2>
 
                <span class="sub-section">Données utilisées</span>
                <p style="text-align: justify;"> Les données qui ont été utilisées dans ce projet viennent d'un dépôt GitHub libre : <a href="https://github.com/CrimsonNynja/monster-hunter-DB/tree/master">https://github.com/CrimsonNynja/monster-hunter-DB/tree/master</a></p>
                <p style="text-align: justify;">Ce sont des données qui proviennent du jeu vidéo Monster Hunter, ces données sont des quêtes de ce même jeu vidéo : un jeu de combat entre chasseur et monstres hyper classes. La particularité des quêtes de Monster Hunter, c'est qu'elles sont simplement construites : un monstre à tuer, le contexte, l'objectif, la carte et la difficulté. Ce qui est parfait pour notre projet. En plus de ça, ce sont des quêtes qui ont un fond d'humour ce qui nous permet de rire malgré le destin du monde qui s'avère bien noir...</p>
            </p>
    
            <p>
                    <span class="sub-section">Prétraitement</span>
                    <ul style="text-align: justify;">
                        <li>Les données du dépôt GitHub sont sous un format JSON avec plusieurs types de balises : target, objective, map, difficulty.</li>
                        <li>Nous avons un total de 844 quêtes pour l'entraînement</li>
                        <li>Extraction du contenu des balises  difficulty, objective, target, description, du corpus json à l'aide du script bla.py  </li>
                        <li>Suite à l'extraction notre corpus est construit sous un format txt de cette forme : </li>
                        <li>Exemple : Map : Desert | Difficulty : easy | Objective : Kill a Rathian | Description blabla....</li>
                        <li>Simplification du corpus en retirant x monstres du corpus. Leurs noms a été synthéthiser , exemple : Apex Nargacuga -> Nargacuga et des maps en retirant x maps</li>
                    </ul>
                
            </p>
            <span class="sub-section">Fine tuning GPT2</span>
            <ul style="text-align: justify;">
                <li>L'entraînement a été réalisé avec le script train.py</li>
                <li>Le modèle utilisé est GPT2 medium pour éviter les longs délais d'entraînement qu'impliquerait la version large.</li>
                <li>Incorporation d'un corpus au format TXT pré-traité avec un format de balise spécifique.</li>
                <li>Apprentissage basé sur des blocs textuels de taille 75, permettant de couvrir intégralement une quête.</li>
                <li>Dix epochs et un batch size de 10 ont été choisis, avec une durée d'entraînement de 30 minutes.</li>
                <li>La génération a été réalisé avec generate.py</li>
                <li>Le prompt spécifie en back end est :  Map : {map} | Diificulty : {level} | Target : {monstres} </li>
                <li>Limitation à 75 max de n-grammes générés pour la génération de texte.</li>
                <li>La température contrôle le niveau de créativité, avec des valeurs plus élevées générant des sorties plus variées mais moins cohérentes.</li>
                <li>Top-K Sampling limite les choix de tokens aux K tokens les plus probables, favorisant la cohérence tout en permettant de la variété.</li>
                <li>Top-P Sampling (Nucleus Sampling) limite la distribution cumulative des probabilités, permettant une génération plus dynamique parmi les tokens les plus probables.</li>
                <li>No Repeat N-Grams empêche la répétition immédiate de séquences de mots pour éviter les motifs répétitifs indésirables.</li>
                <li>Les paramètres de génération peuvent être ajustés pour obtenir les résultats souhaités.</li>
            </ul>
            
        </p>
        <span class="sub-section">FastAPI</span>
        <ul style="text-align: justify;">
<li> Création d'une interface web avec FastAPI</li>
        </ul>
        
    </p>
    
            <p>
                <span class="sub-section">Méthodologie</span>
                <p style="text-align: justify;">Pour sauver le monde, il faut être hyper bien organisé, donc nous nous sommes bien réparties le travail. Qinliang QI s'est occupée de tester le modèle BERT afin de générer des quêtes automatiquement. Natacha MINICONI s'est renseignée sur la conception d'un fine-tuning sur GPT2 afin de construire un modèle de génération automatique. Léna GAUBERT a pré-traité le fichier texte et a évalué le modèle qui sera retenu entre GPT2 et BERT. Par la suite de son évaluation, Qinliang et Natacha ont également regardé cette évaluation. Chaque personne a sa propre perception face aux quêtes générées.</p>
            </p>
    
            <p>

    
            <p>
                <span class="sub-section">Résultats</span>
            </p>
            <p>
                <span class="sub-section">Sources</span>
            </p>
        </div>
    </section>
    
    <section id="evaluation" class="ai-section">
        <h2>Évaluation du Modèle</h2>
        <p>Perspectives d'évaluation, retours des utilisateurs...</p>
    </section>

    <section id="modelbert" class="ai-section">
        <h2>Modèle BERT</h2>
        <p>Informations sur le modèle BERT, problèmes rencontrées...</p>
    </section>
    <section id="contact" class="ai-section">
        <h2>Contact</h2>
        <div style="text-align: center; display: flex; justify-content: center;">

            <div style="margin: 10px;">
                <img src="image/Icon2.jpg" alt="Image 2" style="width: 150px; height: 150px; border-radius: 50%; object-fit: cover;">
                <div style="background-color: rgba(0, 0, 0, 0.5); padding: 10px; color: white; text-align: center;">
                    <p>Natacha Miniconi</p>
                </div>
            </div>
            <div style="margin: 10px;">
                <img src="image3.jpg" alt="Image 3" style="width: 200px; height: 200px; border-radius: 50%; object-fit: cover;">
                <div style="background-color: rgba(0, 0, 0, 0.5); padding: 10px; color: white; text-align: center;">
                    <p>Léna Gaubert</p>
                </div>
            </div>
            <div style="margin: 10px;">
                <img src="image3.jpg" alt="Image 3" style="width: 200px; height: 200px; border-radius: 50%; object-fit: cover;">
                <div style="background-color: rgba(0, 0, 0, 0.5); padding: 10px; color: white; text-align: center;">
                    <p>Qinliang QI</p>
                </div>
            </div>
            <div style="margin: 10px;">
                <img src="image/Icon1.jpg" alt="Image 1" style="width: 150px; height: 150px; border-radius: 50%; object-fit: cover;">
                <div style="background-color: rgba(0, 0, 0, 0.5); padding: 10px; color: white; text-align: center;">
                    <p>Perl</p>
                </div>
            </div>
        </div>
    </section>
    
    
    
    
    
    <footer class="ai-section">
        <p>&copy; 2024 Projet de génération de quête de JDR</p>
    </footer>

</body>
</html>
