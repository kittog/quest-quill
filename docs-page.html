<!DOCTYPE html>
<html lang="en">
<head>
    <title>Quest Quill</title>

    <!-- Meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="description" content="Bootstrap 4 Template For Software Startups">
    <meta name="author" content="Xiaoying Riley at 3rd Wave Media">
    <link rel="shortcut icon" href="favicon.ico">

    <!-- Google Font -->
    <link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700&display=swap" rel="stylesheet">

    <!-- FontAwesome JS-->
    <script defer src="assets/fontawesome/js/all.min.js"></script>

    <!-- Plugins CSS -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.2/styles/atom-one-dark.min.css">
    <link rel="stylesheet" href="assets/plugins/simplelightbox/simple-lightbox.min.css">

    <!-- Theme CSS -->
    <link id="theme-style" rel="stylesheet" href="assets/css/theme.css">

</head>

<body class="docs-page">
    <header class="header fixed-top">
        <div class="branding docs-branding">
            <div class="container-fluid position-relative py-2">
                <div class="docs-logo-wrapper">
					<button id="docs-sidebar-toggler" class="docs-sidebar-toggler docs-sidebar-visible me-2 d-xl-none" type="button">
	                    <span></span>
	                    <span></span>
	                    <span></span>
	                </button>
	                <div class="site-logo"><a class="navbar-brand" href="index.html"><img class="logo-icon me-2" src="assets/images/coderdocs-logo.svg" alt="logo"><span class="logo-text">Quest Quil<span class="text-alt"></span></span></a></div>
                </div><!--//docs-logo-wrapper-->
	            <div class="docs-top-utilities d-flex justify-content-end align-items-center">
	                <div class="top-search-box d-none d-lg-flex">
		                <form class="search-form">
				            <input type="text" placeholder="Search the docs..." name="search" class="form-control search-input">
				            <button type="submit" class="btn search-btn" value="Search"><i class="fas fa-search"></i></button>
				        </form>
	                </div>

					<ul class="social-list list-inline mx-md-3 mx-lg-5 mb-0 d-none d-lg-flex">
						<li class="list-inline-item"><a href="#"><i class="fab fa-github fa-fw"></i></a></li>
			            <li class="list-inline-item"><a href="#"><i class="fab fa-twitter fa-fw"></i></a></li>
		                <li class="list-inline-item"><a href="#"><i class="fab fa-slack fa-fw"></i></a></li>
		                <li class="list-inline-item"><a href="#"><i class="fab fa-product-hunt fa-fw"></i></a></li>
		            </ul><!--//social-list-->
		            <a href="https://themes.3rdwavemedia.com/bootstrap-templates/startup/coderdocs-free-bootstrap-5-documentation-template-for-software-projects/" class="btn btn-primary d-none d-lg-flex">Download</a>
	            </div><!--//docs-top-utilities-->
            </div><!--//container-->
        </div><!--//branding-->
    </header><!--//header-->


    <div class="docs-wrapper">
	    <div id="docs-sidebar" class="docs-sidebar">
		    <div class="top-search-box d-lg-none p-3">
                <form class="search-form">
		            <input type="text" placeholder="Search the docs..." name="search" class="form-control search-input">
		            <button type="submit" class="btn search-btn" value="Search"><i class="fas fa-search"></i></button>
		        </form>
            </div>
		    <nav id="docs-nav" class="docs-nav navbar">
			    <ul class="section-items list-unstyled nav flex-column pb-3">
				    <li class="nav-item section-title"><a class="nav-link scrollto active" href="#section-1"><span class="theme-icon-holder me-2"><i class="fas fa-map-signs"></i></span>Introduction</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-1-1">Objectifs</a></li>

				    <li class="nav-item section-title mt-3"><a class="nav-link scrollto" href="#section-2"><span class="theme-icon-holder me-2"><i class="fas fa-arrow-down"></i></span>Installation</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-2-1">Section Item 2.1</a></li>

				    <li class="nav-item section-title mt-3"><a class="nav-link scrollto" href="#section-3"><span class="theme-icon-holder me-2"><i class="fas fa-box"></i></span>APIs</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-3-1">Données utilisées</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-3-2">Prétraitement</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-3-3">Fine Tunning GPT2</a></li>
				    <li class="nav-item section-title mt-3"><a class="nav-link scrollto" href="#section-4"><span class="theme-icon-holder me-2"><i class="fas fa-cogs"></i></span>Integrations FastAPI</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-4-1">Apparence</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-4-2">Section Item 4.2</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-4-3">Section Item 4.3</a></li>
				    <li class="nav-item section-title mt-3"><a class="nav-link scrollto" href="#section-5"><span class="theme-icon-holder me-2"><i class="fas fa-tools"></i></span>Résultats</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-5-1">Visualisation de certains output et évaluation inter-annotateurs</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-5-2">Évaluation de Quest Quill</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-5-2-1">Évaluation perceptive</a></li>
            <li class="nav-item"><a class="nav-link scrollto" href="#item-5-2-2">Évaluation avec la métrique GRUEN</a></li>
				    <li class="nav-item section-title mt-3"><a class="nav-link scrollto" href="#section-6"><span class="theme-icon-holder me-2"><i class="fas fa-laptop-code"></i></span>Essai Modèle BERT</a></li>
				    <li class="nav-item section-title mt-3"><a class="nav-link scrollto" href="#section-7"><span class="theme-icon-holder me-2"><i class="fas fa-tablet-alt"></i></span>Contact</a></li>
				    <li class="nav-item"><a class="nav-link scrollto" href="#item-7-1">L'équipe</a></li>


			    </ul>

		    </nav><!--//docs-nav-->
	    </div><!--//docs-sidebar-->
	    <div class="docs-content">
		    <div class="container">
			    <article class="docs-article" id="section-1">
				    <header class="docs-header">
					    <h1 class="docs-heading">Quest Quill, qu'est ce que c'est ? <span class="docs-time">Last updated: 2024-02-28</span></h1>
					    <section class="docs-intro">
						    <p>Quest Quill est un générateur de quêtes automatiques auquel l'utilisateur spécifie la carte où il souhaite combattre, le monstre auquel il souhaite se confronter, ainsi que la difficulté globale de la quête désirée.</p>
							<p>Suite aux indications données par l'utilisateur, Quest Quill va générer une quête avec un contexte et un objectif à accomplir.</p>
							<p style="text-align: justify;"><strong>Et pourquoi ?</strong></p>
							<p>Le monde étant en grand danger suite aux multiples attaques de monstres, il nous a semblé urgent de nous entraîner à les combattre à l'aide d'un générateur de quêtes automatiques. Les objectifs de cet entraînement sont,
                dans un premier temps, générer des quêtes avec des conditions telles que : <i>map</i>, <i>difficulté</i>, <i>monstre</i>. Dans un second temps, les quêtes devront être cohérente et présenter quelques touches d'humour.
                (À quoi bon autant s'entraîner si on ne peut pas un petit peu s'amuser...)</p>


						</section><!--//docs-intro-->


				    </header>



			    </article>

			    <article class="docs-article" id="section-2">
				    <header class="docs-header">
					    <h1 class="docs-heading">Installation</h1>
						<section class="docs-intro">

							<head>
						</section><!--//docs-intro-->

				    </header>
				     <section class="docs-section" id="item-2-1">
						<h2 class="section-heading"></h2>
						<p><strong>Pour installer Quest Quill, suivez ces étapes :</strong></p>

						<ol>
							<li>Clonez le dépôt : <code>git clone git@github.com:kittog/quest-quill.git</code></li>
							<li>Accédez au répertoire du projet : <code>cd quest-quill</code></li>
							<li>Installez les dépendances : <code>pip install -r requirements.txt</code></li>
						</ol>
						<p><strong>Pour utiliser Quest Quill, suivez ces étapes :</strong></p>

						<ol>
							<li>Téléchargez le modèle disponible sur WeTransfer.</li>
							<li>Accédez au dossier de l'API : <code>cd/api</code></li>
							<li>Décompressez le fichier .rar téléchargé sur WeTransfer dans le dossier API.</li>
							<li>Exécutez l'application : <code>python -m uvicorn main:app --reload</code></li>
							<li>Suivez les invites pour spécifier les paramètres de la quête tels que la difficulté, le cadre et le type de quête.</li>
							<li>Votre quête est générée ! Nous espérons qu'elle vous plaît !</li>
						</ol>
						<p><strong>Comment générer une quête une fois sur l'interface ?</strong> </p>
						<p>Afin de générer la quête, il faut mentionner dans l'espace dédié:</p>

								<ul>
									<li>La <b>carte</b> où se déroulera la quête pour pouvoir s'acclimater à divers environnements de combat.</li>
									<li>La <b>difficulté</b> de la quête à choisir entre easy, medium, hard</li>
									<li>Le ou les <b>monstres</b> à chasser.</li>
								</ul>				    <style>
									table {
										width: 100%;
										border-collapse: collapse;
									}
									th, td {
										border: 1px solid black;
										padding: 8px;
										text-align: left;
									}
									th {
										background-color: #f2f2f2;
									}
								</style>
							</head>
							<body>

							<h2>Bestiaire A COMPLETER</h2>

							<table>
								<tr>
									<td>Jagras</td>
									<td>Baggi</td>
									<td>Arzuros</td>
									<td>Great Baggi</td>
								</tr>
								<tr>
									<td>Lagombi</td>
									<td>Kulu-Ya-Ku</td>
									<td>Tetranadon</td>
									<td>Aknosom</td>
								</tr>
								<tr>
									<td>Great Izuchi</td>
									<td>Royal Ludroth</td>
									<td>Barroth</td>
									<td>Khezu</td>
								</tr>
								<tr>
									<td>Bishaten</td>
									<td>Somnacanth</td>
									<td>Pukei-Pukei</td>
									<td>Jyuratodus</td>
								</tr>
								<tr>
									<td>Basarios</td>
									<td>Rathian</td>
									<td>Tobi-Kadachi</td>
									<td>Volvidon</td>
								</tr>
								<tr>
									<td>Mizutsune</td>
									<td>Anjanath</td>
									<td>Rathalos</td>
									<td>Almudron</td>
								</tr>
								<tr>
									<td>Goss Harag</td>
									<td>Nargacuga</td>
									<td>Zinogre</td>
									<td>Magnamalo</td>
								</tr>
								<tr>
									<td>Tigrex</td>
									<td>Diablos</td>
									<td>Rajang</td>
									<td>Kushala Daora</td>
								</tr>
								<tr>
									<td>Teostra</td>
									<td>Chameleos</td>
									<td>Wind Serpent Ibushi</td>
									<td>Thunder Serpent Narwa</td>
								</tr>
								<tr>
									<td>Narwa the Allmother</td>
									<td>Crimson Glow Valstrax</td>
									<td>Apex Arzuros</td>
									<td>Apex Rathian</td>
								</tr>
								<tr>
									<td>Apex Mizutsune</td>
									<td>Apex Rathalos</td>
									<td>Apex Diablos</td>
									<td>Apex Zinogre</td>
								</tr>
							</table>

							</body>

							<h2>Map</h2>						</section><!--//section-->

			    </article><!--//docs-article-->


			    <article class="docs-article" id="section-3">
				    <header class="docs-header">
					    <h1 class="docs-heading">APIs</h1>
					    <section class="docs-intro">
<p>Conception de l'API</p>					</section><!--//docs-intro-->
				    </header>
				     <section class="docs-section" id="item-3-1">
						<h2 class="section-heading">Données utilisées</h2>
						<p style="text-align: justify;"> Les données qui ont été utilisées dans ce projet viennent d'un dépôt GitHub libre sous licence MIT : <a href="https://github.com/CrimsonNynja/monster-hunter-DB/tree/master">monster-hunter-DB</a></p>
						<p style="text-align: justify;">Ces données sont des <b>quêtes</b> qui proviennent du jeu vidéo <em>Monster Hunter</em> : un jeu de combat entre chasseurs et monstres (hyper classes et super stylés). La particularité des quêtes de Monster Hunter,
             est qu'elles sont une structure simple : un <b>monstre à tuer</b>, un <b>contexte</b>, un <b>objectif</b>, une <b>carte</b> et une <b>difficulté</b>. Ce qui est parfait pour notre projet.
             En plus de ça, ce sont des quêtes qui ont un <em>fond d'humour</em> ce qui nous permet de rire malgré le destin du monde qui s'avère bien noir...</p>
					</p>					</section><!--//section-->

					<section class="docs-section" id="item-3-2">
						<h2 class="section-heading">Prétraitement</h2>

					<p>
							<ul style="text-align: justify;">
								<li>Les données du dépôt GitHub sont sous un format JSON avec plusieurs types de balises : <code>target</code>, <code>objective</code>, <code>map</code>, <code>difficulty</code>.</li>
								<li>Le corpus d'entraînement est constitué d'un total de <b>848 quêtes</b>.</li>
								<li>À partir de ce corpus, extraction du contenu des balises qui nous intéressent : <code>difficulty</code>, <code>objective</code>, <code>target</code>, <code>description</code>, à l'aide du script <code>bla.py</code>.</li>
								<li>Pour simplifier la visibilité, le rendu de l'API, ainsi que le code, on met le corpus sous format <code>.txt</code> en formattant les quêtes. <b>Exemple : </b> <i>Map : Desert | Difficulty : easy | Objective : Kill a Rathian | Description blabla....</i></li>
                <li>Après quelques essais de génération de quêtes, nous nous sommes rendues compte qu'il y avait <em>trop de monstres</em> à apprendre par rapport au <em>nombre de quêtes</em> dont nous disposions. Nous rencontrions donc
                des soucis dans la génération des objectifs et des descriptions des quêtes.</li>
                <li>Simplification du corpus en retirant <b>12 monstres</b> ainsi que <b>7 maps</b> du corpus. Pour certains monstres, leurs noms ont été synthéthisés.<b> Exemple :</b> <i>Apex Nargacuga → Nargacuga.</i>
                <li>Pour la simplification, on procède avec Notedpad, et on remplace les noms des monstres/maps <b>peu fréquents</b>
              (présents dans moins de 5 quêtes) par des monstres/maps <b>plus fréquents</b>.</li>
							</ul>

					</p>					</section><!--//section-->

					<section class="docs-section" id="item-3-3">
						<h2 class="section-heading">Fine Tuning GPT2</h2>
						<ul style="text-align: justify;">
							<li>L'entraînement a été réalisé avec le script <code>train.py</code></li>
							<li>Le modèle utilisé est <b>GPT2 medium</b> pour éviter les longs délais d'entraînement qu'impliquerait la version <b>large</b>.</li>
							<li>Notre corpus au format <code>.txt</code> est passé en <b>input</b>.</li>
              <br/>
              <b>Choix des paramètres pour l'entraînement :</b>
              <li>Apprentissage basé sur des blocs textuels de <em>taille 75</em>, permettant de couvrir intégralement une quête. (ce choix se justifie par la longueur moyenne d'une quête qui est de 75.)</li>
							<li>L'entraînement se déroule sur <b>10 epochs</b> avec un <b>batch size</b> de <b>10</b>.</li>
              <br/>
              <b>Choix des paramètres pour la génération :</b>
              <li>La génération des quêtes se fait à l'aide du script <code>generate.py</code></li>
							<li>Limitation à <b>75 max de n-grammes générés</b> pour la génération de texte.</li>
							<li>La température contrôle le niveau de créativité. Le choix de valeurs plus élevées génère des sorties plus variées mais moins cohérentes.</li>
							<li><b>Top-K Sampling</b> limite les choix de tokens aux <em>K tokens les plus probables</em>, favorisant la <em>cohérence</em> tout en permettant de la <em>variété</em>.</li>
							<li><b>Top-P Sampling</b> (<i>Nucleus Sampling</i>) limite la <em>distribution cumulative des probabilités</em>, permettant une génération plus <em>dynamique</em> parmi les tokens les plus probables.</li>
							<li><b>No Repeat N-Grams</b> empêche la <em>répétition immédiate</em> de séquences de mots pour éviter les <em>motifs répétitifs indésirables</em>.</li>
							<li>Les paramètres de génération peuvent être ajustés pour obtenir les résultats souhaités.</li>
							<li>Le prompt spécifié en <em>back end</em> est :  <code>Map : {map} | Dificulty : {level} | Target : {monstres}</code> </li>
							<li>Ce prompt permet d'inciter le modèle à générer la suite de la quête → <code>Objectif</code> , <code>Description</code>.</li>
							<li> Nous avons choisi les hyper paramètres pour la génération de <em>manière empirique</em> : au début nous générions des quêtes avec une <b>max length de 175</b>, ce qui était beaucoup trop. Le générateur était alors très incohérent dans les descriptions.</li>
							<li><b>top k</b> et <b>top p</b> ont été utilisés pour que les quêtes générées soient, pour chaque génération utilisant les mêmes prompts, différentes. Au départ, nous obtenions systématiquement la même quête pour certains mots clefs de départ, ce qui n'était pas du tout amusant.</li>

						</ul>

					</p>					</section><!--//section-->
			    </article><!--//docs-article-->

			    <article class="docs-article" id="section-4">
				    <header class="docs-header">
					    <h1 class="docs-heading">Intégration</h1>
					    <section class="docs-intro">
							<ul style="text-align: justify;">
								<li>L'API de Quest Quill fut développée à l'aide du module Python <code>FastAPI</code>.</li>
								<li>L'interface Web développée propose à l'utilisateur d'indiquer les trois critères nécessaire pour la génération de la quête souhaitée. (voir ci-dessous)</li>
                <figure>
                <img src="image/exemple.png">
                <center><figcaption><b>Image 1 — Aperçu de l'interface Web de Quest Quill.</b></figcaption></center>
              </figure>
										</ul>						</section><!--//docs-intro-->
				    </header>

			    </article><!--//docs-article-->

			    <article class="docs-article" id="section-5">
				    <header class="docs-header">
					    <h1 class="docs-heading">Résultats</h1>
					    <section class="docs-intro">
							<ul style="text-align: justify;">
								<li>Une fois que l'utilisateur a rentré ses critères (<code>map</code>, <code>difficulty</code>, et <code>target</code>), Quest-quill génère l'objectif et la description
                correspondants.</li>
								<li>Ci-dessous, un aperçu de l'interface de Quest Quill après la génération d'une quête.</li>
                <figure>
                <img src="image/exemple2.png">
                <center><figcaption><b>Image 2 — Exemple de quête générée avec Quest Quill.</b></figcaption></center>
              </figure>
										</ul>						</section><!--//docs-intro-->
				    </header>
				     <section class="docs-section" id="item-5-1">
						<h2 class="section-heading">
							Visualisation de certains outputs et évaluation inter-annotateurs</h2>
						<ul style="text-align: justify;">
							<li>À notre surprise le modèle génère des quêtes avec <b>peu de fautes de grammaire</b> ou de <b>syntaxe</b>. De plus, les quêtes générées parviennent à reproduire des <b>traits d'humour</b> déjà présents dans les quêtes de référence.</li>
							<li>Nous notons cependant <b>plusieurs erreurs</b> : quelques fois, lorsque nous demandions une quêtes dans la map <b>"desert"</b>, le modèle générait une quête spécifique à la map <b>"arena"</b> (arène), en spécifiant dans la description que l'action se déroulait dans l'arène. Dans
              le questionnaire que nous avons établis pour l'étude perceptive, l'une des quêtes présentées montrait que la map choisie était la jungle, mais la description mentionnait une arène.</li>
							<li>Lorsque <b>plusieurs monstres</b> étaient listés comme <i>cible</i> (target), le modèle a tendance à <b>oublier certains monstres</b> dans la <i>description</i>, voir même à ne pas mentionner le moindre monstre. Cependant, il arrive à prendre
              en compte <b>le nombre de monstres</b> dans l'<i>objectif</i> généré (exemple : <i>Hunt all monsters.</i>)</li>
							<li>Pour les adeptes du jeu, les <b>incohérences produites</b> par notre modèle se repèrent facilement. La génération étant libre (l'utilisateur peut remplir les champs map, difficulty, target comme bon lui semble), nous pouvons créer ces "incohérences". L'intérêt ici est
              de voir si le modèle est capable de générer des combinaison qu'il n'aurait pas rencontrées lors de l'entraînement.</li>
							<li>Par exemple, demander <b>un Diablos en difficulté facile</b> n'est pas courant dans le jeu vidéo : le Diablos est un monstre compliqué à abattre. Une quête facile du jeu serait par exemple de tuer 7 petits monstres. Ainsi, si on demande au modèle de générer
                une quête facile avec pour cible un Diablos, le modèle va donner à l'utilisateur pour mission d'aller <b>chasser 7 Diablos</b>, une tâche loin d'être facile ! Abattre 7 Diablos, c'est dur, voir extrême ! BON COURAGE !</li>

									</ul>

						</p>					</section><!--//section-->

					<section class="docs-section" id="item-5-2">
						<h2 class="section-heading">Évaluation de Quest Quill</h2>
						<ul style="text-align: justify;">

							Il n'y a actuellement <b>pas de consensus</b> quant à l'évaluation des modèles génératifs [Celikyilmaz et. al (2021), C. van der Lee et. al (2020)]. En nous inspirant des pratiques recommendées et de nos recherches personnelles,
              nous avons réalisé une <b>étude perceptive</b>, et fait appel à la <b>métrique GRUEN</b> [Zhu et Bhat (2020)] pour évaluer automatiquement les descriptions des quêtes générées. Ces deux évaluations
              viennent compléter nos premières observations, présentées précédement.
              <br />
              <br />
              <section class="docs-section" id="item-5-2-1">
              <h3 class="section-heading">Évaluation perceptive</h3>
							<li>Pour l'étude perceptive, nous avons créé un formulaire présentant aux participants 10 quêtes, 5 desquelles ont été générées par notre modèle. Les participants ne savent pas quelles quêtes sont générées, mais connaissent la distribution établie pour ce questionnaire. Pour chaque quête, les participants doivent répondre à la même série de question.  Nous interrogeons également les participants sur leur familiarité avec le jeu Monster Hunter.</li>
							<li>L'étude perceptive nous permet d'évaluer le langage et la thématique de chaque quête. Les critères que nous voulions évaluer humainement étaient les suivants : la grammaire, la syntaxe, la cohérence, le langage utilisé pour la quête, et la quantité d'information présente dans la quête. Pour chaque quête, les participants ont un champ de texte libre dans lequel ils peuvent rajouter des observations supplémentaires. </li>
							<li>Les différents critères sont évalués avec des échelles de score allant de 1 à 5 (5 point likert scale).</li>
							<li> <b>Participants :</b> les formulaires furent par la suite partagés sur les réseaux sociaux, à nos ami.e.s, nos proches, et d'autres joueurs de Monster Hunter. Tous les participants n'étaient donc pas nécessairement familier avec le jeu ou l'univers de Monster Hunter.

							<li>Notre étude perceptive ne rassemble pour le moment pas beaucoup de participants (à l'heure où j'écris : 12), mais nous remarquons tout de même une tendance intéressante : le critère sur lequel nous observons le plus de variabilité est la cohérence. Les participants étant familiers avec le jeu sont très souvent ceux qui utilisent les champs de texte libres pour faire part de leurs commentaires. Souvent, c'est le niveau de difficulté qui est remis en cause. Exemples : <i>"Lavasioth is not as dangerous as elder dragons, and three elder dragons make a hard quest, not a medium quest."</i>, <i>"Deviljho and "easy" in the same quest ?"</i></li>
							<li>Les participants relèvent également parfois le manque d'information, ou bien le manque de cohérence entre la map donnée (<i>"What equipment are we talking about?"</i>), et la description qui en nomme une autre (<i>"The description suits an arena quest, not a common quest in the jungle, and Royal Ludroth is not that hard."</i>)</li>
												</section><!--//section-->

					<section class="docs-section" id="item-5-2-2">
							<h3 class="section-heading">Évaluation avec la métrique GRUEN</h3>
              La métrique <b>GRUEN</b> [Zhu et Bhat(2020)] est un score allant de 0 à 1. Plus le score est élevé, meilleur le text généré est (en ne prenant en compte que le langage).
              L'intérêt de la métrique GRUEN est qu'elle évalue l'output du modèle seulement (contrairement à d'autres métriques, développées davantage pour la traduction automatique) selon quatre critères : la grammaticalité, la non-redondance, le "focus" (sujet), la structure et la cohérence. </li>
              <br />
              <br />
              <table>
              <caption>
                <center><strong><b>Table 1 — Scores GRUEN pour 5 de nos quêtes générées</b></strong></center>
              </caption>
              <thead>
                <tr>
                  <th scope="col">QUEST_ID</th>
                  <th scope="col">QUEST</th>
                  <th scope="col">GRUEN</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <th scope="row">1</th>
                  <td>"Yo Ace Ready for some awesome Arena action Prove your mettle using the equipment provided here"</td>
                  <td>0.806</td>
                </tr>
                <tr>
                  <th scope="row">2</th>
                  <td>"It has come to the Board's attention that one of our members may or may not have been seen in the
                    Ancient Forest We are taking this matter seriously and will be contacting our other members should we
                    learn of their location In the meantime seek out and destroy the beast"</td>
                  <td>0.7200</td>
                </tr>
                <tr>
                  <th scope="row">3</th>
                  <td>"I just spotted 7 Diablos I thought they were just goofin' around What could they possibly be doin' up in the Jungle
                     I'm goin' home now Hunter please find out for me"</td>
                  <td>0.6151</td>
                </tr>
                <tr>
                  <th scope="row">4</th>
                  <td>"I've seen my share of Pink Rathian and I still can't wrap my head around how they pull this off They go from pink to purple
                    in a matter of seconds and then there's that rumbling sound and boom I drop all my ingredients on the way back to camp"</td>
                  <td>0.6131</td>
                </tr>
                <tr>
                  <th scope="row">5</th>
                  <td>"The Commander of this expedition has been spotted Subspecies like these are highly valuable to the Commission's research efforts Get going hunter"</td>
                  <td>0.4434</td>
                </tr>
              </tbody>
            </table>
							   </ul>					</section><!--//section-->
               </section>
			    </article><!--//docs-article-->


		        <article class="docs-article" id="section-6">
				    <header class="docs-header">
					    <h1 class="docs-heading">Essai avec BERT</h1>
					    	<ul style="text-align: justify;">
              <li>Le modèle utilisé est <b>BERT</b> — nous cherchions à comparer les performances de ce dernier à <b>GPT-2</b>.</li>
							<li>L'entraînement du modèle a été réalisé à l'aide du script <code>bert.py</code>. Nous avons passé au modèle le même corpus d'entraînement (format <code>.txt</code>) qu'au modèle GPT-2.
              L'entraînement s'est déroulé sur <b>3 epoch</b> avec des batches de taille 4.</li>
							<li>À l'instar du modèle GPT-2, le prompt de quête est construit <b>en fonction des entrées de l'utilisateur</b> :  <code>Map : {map} | Dificulty : {level} | Target : {monstres}</code>.
              Suite à ce prompt, le modèle génère l'<b>objectif</b> et la <b>description</b> de la quête correspondante. La quête générée est finalement
            décodée à l'aide du <em>tokenizer</em>.</li>
              <li>Les résultats obtenus étaient insatisfaisants : le modèle finetuné ne parvenait tout simplement <i>pas à générer des tokens corrects</i>.
                Il était donc <b>impossible</b> d'obtenir, pour un prompt donné, un objectif et une description <i>lisibles</i>.
                Cela est notamment lié à l'architecture de BERT, qui ne dispose pas d'un décodeur, mais <i>seulement</i> d'un <b>encodeur</b> (<i>encoder-only</i>) [Wang & Cho, 2019], ce qui rend difficile leur utilisation pour générer du texte, malgré leur <b>nature bidirectionnelle</b>.
                Cela fait de BERT une exception parmis les LLMs. [Patel et. al, 2023]</li>
                <li><i>Attention</i>, son utilisation pour la génération de texte n'est <i>pas impossible</i> !
                Mais, elle demande plus de travail et de recherche pour guider le modèle comme nous le souhaitons. Dans tous les cas,
                GPT-2 semblait plus adapté pour notre projet.</li>

						</ul>

			    <article class="docs-article" id="section-7">
				    <header class="docs-header">
					    <h1 class="docs-heading">Contact</h1>
					    <section class="docs-intro">
						</section><!--//docs-intro-->
				    </header>
				     <section class="docs-section" id="item-7-1">
						<div style="text-align: center; display: flex; justify-content: center;">

							<div style="margin: 10px;">
								<img src="image/Icon2.jpg" alt="Image 2" style="width: 150px; height: 150px; border-radius: 50%; object-fit: cover;">
								<div style="background-color: rgba(0, 0, 0, 0.5); padding: 10px; color: white; text-align: center;">
									<p>Natacha Miniconi</p>
								</div>
							</div>
							<div style="margin: 10px;">
								<img src="image/Icon3.jpg" alt="Image 3" style="width: 200px; height: 200px; border-radius: 50%; object-fit: cover;">
								<div style="background-color: rgba(0, 0, 0, 0.5); padding: 10px; color: white; text-align: center;">
									<p>Léna Gaubert</p>
								</div>
							</div>
							<div style="margin: 10px;">
								<img src="image/img4.jpg" alt="Image 3" style="width: 200px; height: 200px; border-radius: 50%; object-fit: cover;">
								<div style="background-color: rgba(0, 0, 0, 0.5); padding: 10px; color: white; text-align: center;">
									<p>Qinliang QI</p>
								</div>
							</div>
							<div style="margin: 10px;">
								<img src="image/Icon1.jpg" alt="Image 1" style="width: 150px; height: 150px; border-radius: 50%; object-fit: cover;">
								<div style="background-color: rgba(0, 0, 0, 0.5); padding: 10px; color: white; text-align: center;">
									<p>Perl</p>
								</div>
							</div>					</section><!--//section-->

			    </article><!--//docs-article-->


			    <article class="docs-article" id="section-8">
				    <header class="docs-header">
					    <h1 class="docs-heading">Bibliographie</h1>
					    <section class="docs-intro">
              <p>Monster hunter, Teppen, source métrique léna</p>						</section><!--//docs-intro-->
              <ol>
               <li>Wangzhen Zhu, Suma Bhat (2020):
            <cite>GRUEN for Evaluating Linguistic Quality of Generated Text.</cite></li>
             <li>Celikyilmaz et. al (2021):
          <cite>Evaluation of Text Generation: A Survey.</cite></li>
             <li>van der Lee et. al (2020):
          <cite>Human evaluation of automatically generated text: Current trends and best practice guidelines</cite></li>
        </ol>
            </header>

			    </article><!--//docs-article-->

			    </article><!--//docs-article-->

			    <footer class="footer">
				    <div class="container text-center py-5">
				        <!--/* This template is free as long as you keep the footer attribution link. If you'd like to use the template without the attribution link, you can buy the commercial license via our website: themes.3rdwavemedia.com Thank you for your support. :) */-->
			            <small class="copyright">Designed with <span class="sr-only">love</span><i class="fas fa-heart" style="color: #fb866a;"></i> by <a class="theme-link" href="http://themes.3rdwavemedia.com" target="_blank">Xiaoying Riley</a> for developers</small>
				        <ul class="social-list list-unstyled pt-4 mb-0">
						    <li class="list-inline-item"><a href="#"><i class="fab fa-github fa-fw"></i></a></li>

				        </ul><!--//social-list-->
				    </div>
			    </footer>
		    </div>
	    </div>
    </div><!--//docs-wrapper-->


    <!-- Javascript -->
    <script src="assets/plugins/popper.min.js"></script>
    <script src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>


    <!-- Page Specific JS -->
    <script src="assets/plugins/smoothscroll.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/highlight.min.js"></script>
    <script src="assets/js/highlight-custom.js"></script>
    <script src="assets/plugins/simplelightbox/simple-lightbox.min.js"></script>
    <script src="assets/plugins/gumshoe/gumshoe.polyfills.min.js"></script>
    <script src="assets/js/docs.js"></script>

</body>
</html>
