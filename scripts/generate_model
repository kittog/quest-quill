from transformers import GPT2LMHeadModel, GPT2Tokenizer

model_path = "gpt2_quest_generator_finetuned2"
model = GPT2LMHeadModel.from_pretrained(model_path)
tokenizer = GPT2Tokenizer.from_pretrained(model_path)

# Exemple d'entrée
prompt = "Map: Shrine Ruins | Difficulty: easy | Target: Nargacuga ->"

inputs = tokenizer.encode(prompt, return_tensors='pt')

# Diversification avec la température
outputs = model.generate(inputs, max_length=70, num_return_sequences=1, no_repeat_ngram_size=1)

for i, output in enumerate(outputs):
    generated_text = tokenizer.decode(output, skip_special_tokens=True)
    print(f"Generated text {i+1}: {generated_text}")

